@inproceedings{10.1145/3545945.3569759,
  author    = {Becker, Brett A. and Denny, Paul and Finnie-Ansley, James and Luxton-Reilly, Andrew and Prather, James and Santos, Eddie Antonio},
  title     = {Programming Is Hard - Or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation},
  year      = {2023},
  isbn      = {9781450394314},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3545945.3569759},
  doi       = {10.1145/3545945.3569759},
  abstract  = {The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.},
  booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
  pages     = {500-506},
  numpages  = {7},
  keywords  = {ai, alphacode, amazon, artificial intelligence, code generation, codewhisperer, codex, copilot, cs1, cs2, github, google, gpt-3, introductory programming, large language model, llm, machine learning, midjourney, novice programmers, openai, programming, tabnine},
  location  = {<conf-loc>, <city>Toronto ON</city>, <country>Canada</country>, </conf-loc>},
  series    = {SIGCSE 2023}
}
@article{Baqais2020,
  author   = {Baqais, Abdulrahman Ahmed Bobakr
              and Alshayeb, Mohammad},
  title    = {Automatic software refactoring: a systematic literature review},
  journal  = {Software Quality Journal},
  year     = {2020},
  month    = {Jun},
  day      = {01},
  volume   = {28},
  number   = {2},
  pages    = {459-502},
  abstract = {Refactoring a software artifact is an embedded task in the maintenance phase of the software life cycle. To reduce the time and effort required for this task, researchers proposed methods to automate the software refactoring process at the design and code levels. In this paper, we conducted a systematic literature review of papers that suggest, propose, or implement an automated refactoring process. Using different phases, setting several quality measures, and snowballing, only 41 papers passed to the last stage to be analyzed and reviewed. We observe an increase in the number of papers that propose automatic refactoring. The results show that while most of the papers discuss code refactoring, only a few recent papers are focused on model refactoring. Search-based refactoring is gaining more popularity, and several researchers have used it to perform refactoring in a quick and efficient manner.},
  issn     = {1573-1367},
  doi      = {10.1007/s11219-019-09477-y},
  url      = {https://doi.org/10.1007/s11219-019-09477-y}
}
@article{DEPALMA2024123602,
  title    = {Exploring ChatGPT's code refactoring capabilities: An empirical study},
  journal  = {Expert Systems with Applications},
  volume   = {249},
  pages    = {123602},
  year     = {2024},
  issn     = {0957-4174},
  doi      = {https://doi.org/10.1016/j.eswa.2024.123602},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417424004676},
  author   = {Kayla DePalma and Izabel Miminoshvili and Chiara Henselder and Kate Moss and Eman Abdullah AlOmar},
  abstract = {ChatGPT has shown great potential in the field of software engineering with its ability to generate code. Yet, ChatGPT’s ability to interpret code has been deemed unreliable and faulty, which causes concern for the platform’s ability to properly refactor code. To confront this concern, we carried out a study to assess ChatGPT’s abilities and limitations in refactoring code. We divided the study into three parts: if ChatGPT can refactor the code, if the refactored code preserves the behavior of the original code segments, and if ChatGPT is capable of providing documentation for the refactored code to provide insights into intent, instructions, and impact. We focused our research specifically on eight quality attributes to use when prompting ChatGPT to refactor our dataset of 40 Java code segments. After collecting the refactored code segments from ChatGPT, as well as data on whether the behavior was preserved, we ran the refactored code through PMD, a source code analyzer, to find programming flaws. We also tested ChatGPT’s accuracy in generating documentation for the refactored code and analyzed the difference between the results of each quality attribute. We conclude that ChatGPT can provide many useful refactoring changes that can improve the code quality which is crucial. ChatGPT offered improved versions of the provided code segments 39 out of 40 times even if it is as simple as suggesting clearer names for variables or better formatting. ChatGPT was able to recommend numerous options ranging from minor changes such as renaming methods and variables to major changes such as modifying the data structure. ChatGPT’s strengths and accuracy were in suggesting minor changes because it had difficulty addressing and understanding complex errors and operations. Although most of the changes were minor, they made significant improvements because converting loops, simplifying calculations, and removing redundant statements have a crucial effect on runtime, memory, and readability. However, our results also indicate how ChatGPT can be unpredictable in its responses which threatens the reliability of ChatGPT. Asking ChatGPT the same prompt often yields different results, so some outputs were more accurate than others. This makes it difficult to fully access ChatGPT’s capabilities due to its variation and inconsistency. Due to ChatGPT’s limitations of its reliance on its data set, it lacks understanding of the broader context so it may occasionally make errors and suggest alternations that are neither applicable nor necessary. Overall, ChatGPT has proved to be a beneficial tool for programming as it is capable of providing advantageous suggestions, even if it is on a small scale. However, human programmers are still needed to oversee these changes and determine their significance. ChatGPT should be used as an aid to programmers since we cannot completely depend on it yet.}
}
@book{fowler2018refactoring,
  title     = {Refactoring: Improving the Design of Existing Code},
  author    = {Fowler, M.},
  isbn      = {9780134757704},
  series    = {Addison-Wesley Signature Series (Fowler)},
  url       = {https://books.google.at/books?id=2H1_DwAAQBAJ},
  year      = {2018},
  publisher = {Pearson Education}
}

@article{issueInformation2023,
  title   = {Issue Information},
  author  = {Chitti Babu Karakati, Sethukarasi Thirumaaran},
  journal = {Concurrency and Computation: Practice and Experience},
  year    = {2023},
  volume  = {35},
  number  = {4},
  pages   = {e7073},
  note    = {e7073},
  issn    = {1532-0626},
  doi     = {10.1002/cpe.7073},
  url     = {https://doi.org/10.1002/cpe.7073}
}