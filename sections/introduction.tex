According to Fowler \cite{fowler2018refactoring}, refactoring involves modifying a software system to enhance its internal structure without changing its external behaviour. Numerous empirical studies have demonstrated a direct link between refactoring activities and improvements in code quality metrics. This body of evidence underscores the critical importance of refactoring in software engineers' priorities. \cite{aniche2020effectiveness}.\\
However, deciding when and how to refactor can be challenging for developers. Refactoring in an early stage may cost too in regards to potential benefits, and refactoring too late may cause the refactor to be an even more significant time commitment \cite{kruchten2012technical}.\\
Tools have been in the hands of many developers to make this process more streamlined for years. Analytics tools such as PMD, ESLint, and Sonarqube can be integrated into various stages of a developer's workflow (within IDEs, during code reviews, or as comprehensive quality reportsâ€”to identify bugs and provide suggestions for enhancing code quality)\cite{aniche2020effectiveness}.\\
Taking a closer look at these tools, however, reveals that they commonly have a lot of false positives, forcing developers to double-check their results more often than not. In some cases, the detection strategies are based on hard thresholds of just a handful of metrics, such as lines of code in a file (e.g. PMD's famous "problematic" classification occurring once a method reaches 100 lines per default)\cite{aniche2020effectiveness}. These simplistic ways of detection cannot cover the complexity of modern systems.\\
Manually analyzing hundreds of metrics and figuring out which ones are the cause of technical dept is very hard and almost impossible for tool developers, which is where machine learning-based solutions come into play \cite{leitch2003maintainability}.\\
We will take a closer look at how exactly different models go about this task in section \ref{automation}
